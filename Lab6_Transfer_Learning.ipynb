{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IXelAlZrGs0o"
   },
   "source": [
    "#Сверточные нейронные сети (Convolutional Neural Network, CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vpNGKmcJG27x"
   },
   "source": [
    "В прошлой работе мы разобрали структуру нейронной сети, а точнее прямо распространяющуюся нейронную сеть. В этот раз мы поговорим о другом типе нейронных сетей - сверточные. Возьмем двумерную сверточную сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-UdI3DDOHvLZ"
   },
   "source": [
    "Сверточные сети построены на операции свертки.\n",
    "\n",
    "Имеется ядро – небольшая матрица весов. Это ядро «скользит» по двумерным входным данным, выполняя поэлементное умножение для той части данных, которую сейчас покрывает. Результаты перемножений ячеек суммируются в одном выходном пикселе. В случае сверточных нейросетей ядро определяется в ходе обучения сети. \n",
    "\n",
    "Перемножение и суммирование повторяются для каждой локации, по которой проходит ядро. Двумерная матрица входных признаков преобразуется в двумерную матрицу выходных. Выходные признаки, таким образом, являются взвешенными суммами входных признаков. Число входных признаков в комбинации для одного выходного признака определяет размер ядра."
   ]
  },
  
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zhxYG9QR2EqL"
   },
   "source": [
    "![convUrl](https://media.proglib.io/wp-uploads/2018/06/2.gif \"Convolution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WffTQbEm2ZU7"
   },
   "source": [
    "\n",
    "\n",
    "Если представить находящуюся выше матрицу 5х5 как картинку: матрицу интенсивности пикселей, где 0 это черный, а 3 это белый, а 1 и 2 темно-серый и светло-серый, то получим некоторую картинку, к которой применяем нашу свертку - квадрат 3х3. На данной картинке это квадрат со значениями 0,1,2,2,2,0,0,1,2. Применяем свертку, то есть перемножаем ячейки свертки и картинки. Например, для первой ячейки выходной матрицы:\n",
    "\n",
    "\n",
    "$3*0+3*1+2*2+0*2+0*2+1*0+3*0+1*1+2*2=12$\n",
    "\n",
    "В целом, мы подаем на вход картинку, а получаем на выходе рассчитанные по ней коэффициенты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vw2K1BACsVGb"
   },
   "source": [
    "# Многоканальность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELbnCvKxsf02"
   },
   "source": [
    "Если раньше мы работали с черно-белыми изображениями, то в этот раз изображения цветные. Поэтому вместо одного канала мы теперь имеем три - по числу цветов RGB модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OHQIBdXDtZgj"
   },
   "source": [
    "![channelsUrl](https://neurohive.io/wp-content/uploads/2018/07/rgb-svertochnaja-neiroset.gif \"Сhannels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o7Tq2ULLtxWf"
   },
   "source": [
    "Свертка проходит по каждому из каналов, а затем суммирует их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oOSTXr6Btljn"
   },
   "source": [
    "![channelsSumUrl](https://neurohive.io/wp-content/uploads/2018/07/glubokaja-svertochnaja-neironnaja-set.gif \"Сhannels_Sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yXzk_MMkt0ll"
   },
   "source": [
    "Таким образом,  нейронная сеть будет принимать на вход изображения размером nxn и 3 канала. Например, (150,150,3), как в нашей сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ws06a1MgsGEi"
   },
   "source": [
    "# Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TiqsKS2hsLoy"
   },
   "source": [
    "Еще один специальный слой, явяющийся подвыборочным. Он используется с целью уменьшения размерности предыдущего слоя. Если на предыдущей операции свертки уже были выявлены некоторые признаки, то для дальнейшей обработки настолько подробное изображение уже не нужно, и оно уплотняется до менее подробного. К тому же фильтрация уже ненужных деталей помогает не переобучаться.\n",
    "\n",
    "Чаще всего используется уменьшение изображения в два раза путем использования матрицы 2х2 через операцию взятия максимума."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Ozs7uuJwY15"
   },
   "source": [
    "# Теперь поговорим о предобученных сетях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yHHpP_7NwgTV"
   },
   "source": [
    "Обучение нейронной сети занимает не только много времени, но и требует большой размеченной выборки. Конечно, можно создавать свои сети с нуля и подбирать сеть для каждого конкретного случая. А можно упростить себе жизнь и взять для нашей задачи уже готовую нейронную сеть, обученную в течение долгого времени и показавшую хорошие результаты на своей задаче. Такая техника называется Transfer Learning или Перенос обучения.\n",
    "\n",
    "То есть, Transfer Learning - это процесс дообучения на новых данных какой-либо нейросети, уже обученной до этого на других данных, обычно на каком-нибудь хорошем, большом (миллионы картинок) датасете.\n",
    "\n",
    "Например, у нас есть сеть, хорошо распознающая самолет на картинке или танк. А мы хотим применить ее для распознавания кошек и собак. Так как на первых слоях нейронной сети происходит общая оценка изображения и мы не успеваем дойти до специфичных признаков, мы можем использовать такую сеть для распознавания котов и собак.\n",
    "\n",
    "Есть три основных пути:\n",
    "* Взять предобученную на других данных нейронную сеть и просто предсказать наши картинки:\n",
    "\n",
    " +Не надо тратить время на обучение\n",
    "\n",
    " -Точность будет низкая для нашей задачи, если она сильно отличается\n",
    "\n",
    "* Взять предобученную на других данных нейронную сеть, добавить к ней новые слои и обучить только их\n",
    "\n",
    " +Сокращается время на обучение, происходит подгон под нашу задачу\n",
    "\n",
    " -Точность будет выше, однако добавление новых слоев может перегрузить сеть\n",
    "\n",
    "* Взять предобученную на других данных нейронную сеть, добавить новые слои. Но вместе с тем обучить не только новые слои, но и часть предобученной сети. Этот метод носит название Fine Tuning или Тонкая настройка.\n",
    "\n",
    " +Обучается не вся сеть, а только часть, отвечающая за специфичные признаки изображения\n",
    "\n",
    " -Точность должна возрасти, однако вероятно переобучение\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KKHzuWHG0evx"
   },
   "source": [
    "В зависимости от количества и природы Ваших данных есть выбор из нескольких стратегий Transfer Learning, а именно:\n",
    "\n",
    "* *У Вас **мало данных** ($\\le$ 10k), и они **похожи** на данные, на которых была обучена сеть до этого*  \n",
    "\n",
    "Можно использовать просто готовую модель. Но если точность вышла низкая, можно использовать второй путь. Если применить Fine-Tuning (3 способ), то сеть может переобучиться, поскольку данных мало.\n",
    "* *У Вас **мало данных** ($\\le$ 10k), и они **не похожи** на данные, на которых была обучена сеть до этого*  \n",
    "\n",
    "Самый плохой вариант. Хорошим выходом будет второй вариант, но возможно придется выкинуть часть последних слоев преобученной сети и тогда уже добавить свой.\n",
    "* *У Вас **много данных** ($\\ge$ 10k), и они **похожи** на данные, на которых была обучена сеть до этого*  \n",
    "\n",
    "Fine Tuning здесь подходит больше всего.\n",
    "* *У Вас **много данных** ($\\ge$ 10k), и они **не похожи** на данные, на которых была обучена сеть до этого*\n",
    "\n",
    "Обычно здесь оставляют архитектуру сети и используют запомненные веса как начальные. А потом заново обучают всю сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XKVOY5WT29xU"
   },
   "source": [
    "Нашей стратегией в этой работе будет первый вариант."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSO4NFDLZhDF"
   },
   "source": [
    "# Предобученная сеть VGG-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiBRxnlMxgT8"
   },
   "source": [
    "VGG-16 — модель сверточной нейронной сети, предложенная K. Simonyan и A. Zisserman из Оксфордского университета в статье “Very Deep Convolutional Networks for Large-Scale Image Recognition”. Модель достигает точности 92.7% — топ-5, при тестировании ImageNet в задаче распознавания объектов на изображении. Этот датасет состоит из более чем 14 миллионов изображений, принадлежащих к 1000 классам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VGivCyLzaslA"
   },
   "source": [
    "Архитектуру данной сети вы можете увидеть на картинке.\n",
    "\n",
    "На момент создания VGG люди уже заметили, что чем больше слоев в нейросети, тем выше ее точность. Заменяя большие фильтры на несколько фильтров 3$\\times$3 исследователи получили глубокую нейросеть с меньшим количеством параметров. Архитектура VGG-16 (версии VGG с 16 слоями) представлена на картинке ниже:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXXirCVqaslE"
   },
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1040/1*0Tk4JclhGOCR_uLe6RKvUQ.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hyiBl5hsaslJ"
   },
   "source": [
    "Когда говорят VGG, то чаще всего имеют ввиду VGG-16 или VGG-19. Более глубоких версий VGG нет, так как после 19 слоев точность начинает падать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRWqz65kGz1H"
   },
   "source": [
    "#Основные шаги по выполнению лабораторной работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8BNBKwW8d7Ik"
   },
   "source": [
    "##Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36v49-4elSNS"
   },
   "source": [
    "Для начала работы подготовим данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vBHKF8dWeCbB"
   },
   "source": [
    "Скачайте файл train.zip с набором изображений кошек и собак с сайта соревнования Kaggle [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/data) и распакуйте его. Создайте папку cat_dogs (нажиамем правой кнопкой где-нибудь в поле, где находится sample_data, нажимаем new folder) и сделайте upload для 500 снимков кошек (cat0.jpg-cat499.jpg) и 500 собак (dog0.jpg-dog499.jpg). \n",
    "\n",
    "Чем на большем объеме данных будет обучаться ваша сеть, тем лучше, но это так же сильно увеличит время обучения сети. В реальных задачах это нормально, если  обучение нейронной сети на большом объеме данных занимает более 12 часов.  При обучении на всех изображениях точность продемонстрированных ниже сетей будет достигать 97%.\n",
    "\n",
    "В рамках данной работы мы возьмем только 500 изображений, для экономии учебного времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xu4nR89RlT75"
   },
   "source": [
    "Распределим эти фотографии по папкам: train, test и val. \n",
    "\n",
    "Каждая папка будет содержать две подпапки: cats и dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "vfqGmdHydEde",
    "outputId": "6885cd3e-b011-4b17-8f32-afd7c856144c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WlMsw3Zd_I-"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5A2gTOfeO7Z"
   },
   "outputs": [],
   "source": [
    "# Каталог с набором данных\n",
    "data_dir = './cat_dogs/'\n",
    "# Каталог с данными для обучения\n",
    "train_dir = 'train'\n",
    "# Каталог с данными для проверки\n",
    "val_dir = 'val'\n",
    "# Каталог с данными для тестирования\n",
    "test_dir = 'test'\n",
    "# Часть набора данных для тестирования\n",
    "test_data_portion = 0.15\n",
    "# Часть набора данных для проверки\n",
    "val_data_portion = 0.15\n",
    "# Количество элементов данных в одном классе\n",
    "nb_images = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCdpOq3Qlu6a"
   },
   "source": [
    "Функция создания каталога с двумя подкаталогами по названию классов: cats и dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aO_T8vYky5U"
   },
   "outputs": [],
   "source": [
    "def create_directory(dir_name):\n",
    "    if os.path.exists(dir_name):\n",
    "        shutil.rmtree(dir_name)\n",
    "    os.makedirs(dir_name)\n",
    "    os.makedirs(os.path.join(dir_name, \"cats\"))\n",
    "    os.makedirs(os.path.join(dir_name, \"dogs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VmcuPGK8lymp"
   },
   "source": [
    "Создание структуры каталогов для обучающего, проверочного и тестового набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dr3fie4uk3Au"
   },
   "outputs": [],
   "source": [
    "create_directory(train_dir)\n",
    "create_directory(val_dir)\n",
    "create_directory(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xUwnLmCl0uA"
   },
   "source": [
    "\n",
    "Функция копирования изображений в заданный каталог. Изображения котов и собак копируются в отдельные подкаталоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "paGtIfMCk-Dk"
   },
   "outputs": [],
   "source": [
    "def copy_images(start_index, end_index, source_dir, dest_dir):\n",
    "    for i in range(start_index, end_index):\n",
    "        shutil.copy2(os.path.join(source_dir, \"cat.\" + str(i) + \".jpg\"), \n",
    "                    os.path.join(dest_dir, \"cats\"))\n",
    "        shutil.copy2(os.path.join(source_dir, \"dog.\" + str(i) + \".jpg\"), \n",
    "                   os.path.join(dest_dir, \"dogs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fSgB_lVGl297"
   },
   "source": [
    "\n",
    "Расчет индексов наборов данных для обучения, проверки и тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "clDnZ7i3lAAY",
    "outputId": "3149fd88-e5be-4505-de03-ac36b534b5f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "425\n"
     ]
    }
   ],
   "source": [
    "start_val_data_idx = int(nb_images * (1 - val_data_portion - test_data_portion))\n",
    "start_test_data_idx = int(nb_images * (1 - test_data_portion))\n",
    "print(start_val_data_idx)\n",
    "print(start_test_data_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G5A2Ks-AmHDr"
   },
   "source": [
    "Копирование изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-I1T0i57lCUf"
   },
   "outputs": [],
   "source": [
    "copy_images(0, start_val_data_idx, data_dir, train_dir)\n",
    "copy_images(start_val_data_idx, start_test_data_idx, data_dir, val_dir)\n",
    "copy_images(start_test_data_idx, nb_images, data_dir, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dDZMkIv4mDBB"
   },
   "source": [
    "## Создание нейронной сети на базе предварительно обученной нейронной сети VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fijrMm_43PNg"
   },
   "source": [
    "Сеть VGG16 ранее обучалась на похожих изображениях. Поэтому мы попробуем два способа:\n",
    "* добавим свои слои к сети VGG16, но саму сеть обучать не будем\n",
    "* разморозим только последний слой сети VGG16 и обучим с новыми слоями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AVuVnIXmmYO_"
   },
   "source": [
    "### Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "of2jctaTlFst",
    "outputId": "ea8ec8c4-cd71-44b8-b165-189296393b69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.python.keras.applications import VGG16\n",
    "from tensorflow.python.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hCRdvqBEmnL5"
   },
   "source": [
    "Определим оставшиеся константы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRVEMD9mmqt8"
   },
   "outputs": [],
   "source": [
    "# Размеры изображения\n",
    "img_width, img_height = 150, 150\n",
    "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
    "input_shape = (img_width, img_height, 3)\n",
    "# Размер мини-выборки\n",
    "batch_size = 64\n",
    "# Количество изображений для обучения\n",
    "nb_train_samples = 700\n",
    "# Количество изображений для проверки\n",
    "nb_validation_samples = 150\n",
    "# Количество изображений для тестирования\n",
    "nb_test_samples = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1A1H5k3pmQk"
   },
   "source": [
    "Следующей строчкой мы загрузим предварительно обученную сеть VGG16. Сразу установим входную размерность, а именно 150 пикселей ширины на 150 пикселей выосоты на 3 канала цвета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "ULsV6Ua9paeh",
    "outputId": "5d7d8f5f-ba69-4de8-823b-88bd5d95d36f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg16_net = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "syeEUTWdpv3V"
   },
   "source": [
    "\"Замораживаем\" веса предварительно обученной нейронной сети VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OyKAKsvp1CA"
   },
   "outputs": [],
   "source": [
    "vgg16_net.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4BfTGV7p4hT"
   },
   "source": [
    "Посмотрим на структуру загруженной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "colab_type": "code",
    "id": "O-kFTd-Vp2ZH",
    "outputId": "c021cf3f-f4f0-4bd7-c160-9cb68e88fd56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQeY63qWp-Lq"
   },
   "source": [
    "Теперь давайте добавим к имеющейся сети несколько новых слоев. Возьмем выходные данные VGG16 нейронной сети и подадим их на вход нашего нового слоя Flatten, который преобразует эти данные в одномерный вектор. \n",
    "\n",
    "Dense - это уже знакомый нам полносвязный слой. \n",
    "\n",
    "Дальше идет слой Dropout, который \"исключает\" заданный процент нейронов. “Исключение” нейрона означает, что при любых входных данных или параметрах он возвращает 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RYK_n8BSp3-h"
   },
   "outputs": [],
   "source": [
    "x = vgg16_net.output\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=vgg16_net.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLEW79IvrTMB"
   },
   "source": [
    "Посмотрим на структуру получившейся составной сети. Мы можем увидеть новые слои в конце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "colab_type": "code",
    "id": "rm5oylmHrSt0",
    "outputId": "87ea5767-a4fc-460b-84bd-99fedd5f9da9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "Pam3-x0ErZ2n",
    "outputId": "49c367d9-768e-4935-fd55-154728080cc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=1e-5), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8zy3cvLfsC3c"
   },
   "source": [
    "### Создаем генератор изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PT8hvopFpUBG"
   },
   "source": [
    "Еще один способ подать данные в сеть - это с помощью генератора изображений. Процесс предподготовки данных (например,оптимальное разбитие на выборки, нормализация или изменения размера изображения) имеет большое значение для нейронных сетей. Некоторые из этих процессов можно прописывать отдельно, а можно применить генератор изображений. \n",
    "\n",
    "В данном случае мы сделаем несколько вещей при помощи генератора:\n",
    "* Нормализуем данные\n",
    "* Изменим размерность картинок на подходящий в нейронную сеть\n",
    "* Пропишем размер мини-выборки\n",
    "\n",
    "Мы уже сталкивались с данными, в которых представителей одного класса больше, чем других. В таком случае часто применяется искуственная генерация изображений. Например, путем поворота или отражения картинки, увеличения или уменьшения, размытия четкоси. Все это позволяет делать генератор изображений, однако в данной работы мы не будем останавливаться на этом. Используем генератор для описанных выше целей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VJ-vB0oNsT7R"
   },
   "source": [
    "Итак, генератор изображений создается на основе класса ImageDataGenerator. Генератор делит значения всех пикселов изображения на 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZci8neOrojf"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3QkgZRysX8n"
   },
   "source": [
    "\n",
    "Генератор данных для обучения, проверки и тестирования на основе изображений из каталога"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0B3_JBn3sIBx",
    "outputId": "63ba2cdf-d962-4891-92c7-1e2583e202ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 700 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3RJ-H3c7sJVu",
    "outputId": "9be162e3-a41c-409b-922f-98b9a9002683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gVRDyRIqsLTh",
    "outputId": "8455f18d-ae66-44c5-89b0-0c52222e42bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XbSvJo2LsgDh"
   },
   "source": [
    "### Обучаем модель с использованием генераторов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "lAIVYY9esNE3",
    "outputId": "d108527e-1a12-4935-a3c0-ba2f5e94b745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.8842 - acc: 0.4931Epoch 1/10\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.8577 - acc: 0.5142 - val_loss: 0.7386 - val_acc: 0.4688\n",
      "Epoch 2/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.7691 - acc: 0.5332Epoch 1/10\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.7661 - acc: 0.5456 - val_loss: 0.6907 - val_acc: 0.5391\n",
      "Epoch 3/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.7413 - acc: 0.5538Epoch 1/10\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.7377 - acc: 0.5535 - val_loss: 0.6513 - val_acc: 0.6406\n",
      "Epoch 4/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6429 - acc: 0.6189Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.6484 - acc: 0.6164 - val_loss: 0.6220 - val_acc: 0.6719\n",
      "Epoch 5/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6491 - acc: 0.6198Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.6416 - acc: 0.6336 - val_loss: 0.5953 - val_acc: 0.7109\n",
      "Epoch 6/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6274 - acc: 0.6469Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.6283 - acc: 0.6494 - val_loss: 0.5711 - val_acc: 0.7578\n",
      "Epoch 7/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.5783 - acc: 0.6736Epoch 1/10\n",
      "10/10 [==============================] - 173s 17s/step - loss: 0.5828 - acc: 0.6609 - val_loss: 0.5509 - val_acc: 0.7500\n",
      "Epoch 8/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.5652 - acc: 0.6958Epoch 1/10\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.5664 - acc: 0.6950 - val_loss: 0.5319 - val_acc: 0.7500\n",
      "Epoch 9/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.5163 - acc: 0.7378Epoch 1/10\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.5199 - acc: 0.7343 - val_loss: 0.5142 - val_acc: 0.7969\n",
      "Epoch 10/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.5242 - acc: 0.7430Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.5272 - acc: 0.7389 - val_loss: 0.5002 - val_acc: 0.7891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc25af2a4a8>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "doc9og1dtSRp"
   },
   "source": [
    "### Оценим качество сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UXvmyb4Csjwa",
    "outputId": "34279419-6994-47d5-aad2-cedccca29104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аккуратность на тестовых данных: 81.25%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4ddL6UctpPX"
   },
   "source": [
    "### Применение метода Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6fDPVYrztwFd"
   },
   "source": [
    "\"Размораживаем\" последний сверточный блок сети VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iwp6Z_nZtzP5"
   },
   "outputs": [],
   "source": [
    "vgg16_net.trainable = True\n",
    "trainable = False\n",
    "for layer in vgg16_net.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        trainable = True\n",
    "    layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ix4pEQ2t8KE"
   },
   "source": [
    "Посмотрим на количество обучаемых параметров, оно должно было измениться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 961
    },
    "colab_type": "code",
    "id": "N3Za9hQ9xAyn",
    "outputId": "df089d11-0c5c-46e4-b751-e9cd14d7b5f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "Total params: 9,732,929\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t7NpYe7euD2T"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=1e-5), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKg3y9gc34YX"
   },
   "source": [
    "Возьмем небольшое количество эпох, чтобы избежать переобучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "79yXfK-3uHeg",
    "outputId": "7a46ebe9-dc69-4aea-c88d-5591a24b3178"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 9/10 [==========================>...] - ETA: 17s - loss: 0.4900 - acc: 0.7395Epoch 1/2\n",
      "10/10 [==============================] - 204s 20s/step - loss: 0.4853 - acc: 0.7469 - val_loss: 0.4455 - val_acc: 0.8203\n",
      "Epoch 2/2\n",
      " 9/10 [==========================>...] - ETA: 17s - loss: 0.3772 - acc: 0.8392Epoch 1/2\n",
      "10/10 [==============================] - 203s 20s/step - loss: 0.3854 - acc: 0.8286 - val_loss: 0.4063 - val_acc: 0.8047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc2573e1668>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=2,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XRbXQ4F0uKf1",
    "outputId": "7f086a69-e902-4a74-81fc-d00a3582e2cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аккуратность на тестовых данных: 85.94%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8fRk2VpJzgYJ"
   },
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cRk_Fw1zj2q"
   },
   "source": [
    "1.  Запустите код, приведенный для примера, выше (обучите сети, проанализируйте результаты)\n",
    "2. Создайте собвтенную нейронную сеть на базе предобученной сети VGG16 (можно взять другую предобученную сеть по желанию, например, AlexNet, Interception и  т.д). \n",
    "\n",
    "То есть в примере выше нужно поменять добавляемые слои после Flattern на ваш вариант. Например, вы можете использовать:\n",
    "* Один дополнительный полносвязный слой Dense после Dropout\n",
    "* Dropout с разным процентом исключения нейронов\n",
    "* Также вы можете поменять количество эпох или размер мини-выборки\n",
    "\n",
    "3. Сравните полученные результаты и сделайте выводы.\n",
    "\n",
    "! не забудьте заново загрузить VGG16 или снова заморозить все слои в уже загруженной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hoz5GvIrwR0j"
   },
   "source": [
    "нейронка с еще одним Dense после Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "P5-hFk3Pu9z7",
    "outputId": "f4b7ec02-5552-49ff-fa35-f819856f6f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.7030 - acc: 0.5350Epoch 1/10\n",
      "10/10 [==============================] - 170s 17s/step - loss: 0.7030 - acc: 0.5330 - val_loss: 0.6812 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6905 - acc: 0.5559Epoch 1/10\n",
      "10/10 [==============================] - 169s 17s/step - loss: 0.6873 - acc: 0.5660 - val_loss: 0.6682 - val_acc: 0.5312\n",
      "Epoch 3/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6574 - acc: 0.6364Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.6543 - acc: 0.6384 - val_loss: 0.6527 - val_acc: 0.6094\n",
      "Epoch 4/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6541 - acc: 0.6146Epoch 1/10\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.6527 - acc: 0.6187 - val_loss: 0.6392 - val_acc: 0.6406\n",
      "Epoch 5/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6501 - acc: 0.6276Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.6505 - acc: 0.6242 - val_loss: 0.6253 - val_acc: 0.6562\n",
      "Epoch 6/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6283 - acc: 0.6567Epoch 1/10\n",
      "10/10 [==============================] - 169s 17s/step - loss: 0.6248 - acc: 0.6646 - val_loss: 0.6119 - val_acc: 0.6875\n",
      "Epoch 7/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6082 - acc: 0.6667Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.6124 - acc: 0.6641 - val_loss: 0.5999 - val_acc: 0.7188\n",
      "Epoch 8/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.5993 - acc: 0.6871Epoch 1/10\n",
      "10/10 [==============================] - 170s 17s/step - loss: 0.6036 - acc: 0.6840 - val_loss: 0.5868 - val_acc: 0.7266\n",
      "Epoch 9/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.5704 - acc: 0.7394Epoch 1/10\n",
      "10/10 [==============================] - 170s 17s/step - loss: 0.5698 - acc: 0.7453 - val_loss: 0.5750 - val_acc: 0.7266\n",
      "Epoch 10/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.5579 - acc: 0.7726Epoch 1/10\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.5589 - acc: 0.7719 - val_loss: 0.5630 - val_acc: 0.7344\n",
      "Аккуратность на тестовых данных: 77.34%\n"
     ]
    }
   ],
   "source": [
    "vgg16_net1 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "vgg16_net1.trainable = False\n",
    "x = vgg16_net1.output\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model1 = Model(inputs=vgg16_net1.input, outputs=predictions)\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=1e-5), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "scores = model1.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YuSqqMuzxfdF"
   },
   "source": [
    "нейронка с Dropout с разным процентом исключения нейронов (увеличилось время работы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "6Fsjut2Tu9wh",
    "outputId": "089ae123-0063-43bd-ed24-11ab0840945e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.8128 - acc: 0.5192Epoch 1/10\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.8069 - acc: 0.5142 - val_loss: 0.6979 - val_acc: 0.5547\n",
      "Epoch 2/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.7030 - acc: 0.5399Epoch 1/10\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.7049 - acc: 0.5377 - val_loss: 0.6483 - val_acc: 0.6484\n",
      "Epoch 3/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6786 - acc: 0.5857Epoch 1/10\n",
      "10/10 [==============================] - 173s 17s/step - loss: 0.6756 - acc: 0.5896 - val_loss: 0.6117 - val_acc: 0.6875\n",
      "Epoch 4/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6203 - acc: 0.6434Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.6186 - acc: 0.6399 - val_loss: 0.5881 - val_acc: 0.7188\n",
      "Epoch 5/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6020 - acc: 0.6493Epoch 1/10\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.5988 - acc: 0.6516 - val_loss: 0.5584 - val_acc: 0.7578\n",
      "Epoch 6/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.5755 - acc: 0.6836Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.5712 - acc: 0.6887 - val_loss: 0.5298 - val_acc: 0.7969\n",
      "Epoch 7/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.5385 - acc: 0.7238Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.5369 - acc: 0.7264 - val_loss: 0.5089 - val_acc: 0.8047\n",
      "Epoch 8/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.5151 - acc: 0.7570Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.5155 - acc: 0.7563 - val_loss: 0.4885 - val_acc: 0.8047\n",
      "Epoch 9/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.5091 - acc: 0.7605Epoch 1/10\n",
      "10/10 [==============================] - 170s 17s/step - loss: 0.5108 - acc: 0.7563 - val_loss: 0.4743 - val_acc: 0.8203\n",
      "Epoch 10/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.4578 - acc: 0.7986Epoch 1/10\n",
      "10/10 [==============================] - 173s 17s/step - loss: 0.4580 - acc: 0.7969 - val_loss: 0.4610 - val_acc: 0.8281\n",
      "Аккуратность на тестовых данных: 82.81%\n"
     ]
    }
   ],
   "source": [
    "vgg16_net2 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "vgg16_net2.trainable = False\n",
    "x = vgg16_net2.output\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model2 = Model(inputs=vgg16_net2.input, outputs=predictions)\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=1e-5), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "scores = model2.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "colab_type": "code",
    "id": "Jhf66Npdu9uX",
    "outputId": "133a0735-b053-4b10-872b-da952151682d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.8803 - acc: 0.4808Epoch 1/10\n",
      "10/10 [==============================] - 170s 17s/step - loss: 0.8733 - acc: 0.4874 - val_loss: 0.7131 - val_acc: 0.4922\n",
      "Epoch 2/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.8665 - acc: 0.4930Epoch 1/10\n",
      "10/10 [==============================] - 170s 17s/step - loss: 0.8591 - acc: 0.5031 - val_loss: 0.6757 - val_acc: 0.5859\n",
      "Epoch 3/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.8169 - acc: 0.5385Epoch 1/10\n",
      "10/10 [==============================] - 169s 17s/step - loss: 0.8090 - acc: 0.5409 - val_loss: 0.6470 - val_acc: 0.6797\n",
      "Epoch 4/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.7655 - acc: 0.5660Epoch 1/10\n",
      "10/10 [==============================] - 170s 17s/step - loss: 0.7637 - acc: 0.5656 - val_loss: 0.6251 - val_acc: 0.7188\n",
      "Epoch 5/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.7395 - acc: 0.5734Epoch 1/10\n",
      "10/10 [==============================] - 169s 17s/step - loss: 0.7230 - acc: 0.5802 - val_loss: 0.6052 - val_acc: 0.7578\n",
      "Epoch 6/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6772 - acc: 0.6074Epoch 1/10\n",
      "10/10 [==============================] - 168s 17s/step - loss: 0.6728 - acc: 0.6139 - val_loss: 0.5831 - val_acc: 0.7500\n",
      "Epoch 7/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6884 - acc: 0.6042Epoch 1/10\n",
      "10/10 [==============================] - 170s 17s/step - loss: 0.6784 - acc: 0.6125 - val_loss: 0.5636 - val_acc: 0.7344\n",
      "Epoch 8/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6324 - acc: 0.6294Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.6330 - acc: 0.6352 - val_loss: 0.5495 - val_acc: 0.7500\n",
      "Epoch 9/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6200 - acc: 0.6818Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.6051 - acc: 0.6918 - val_loss: 0.5375 - val_acc: 0.7734\n",
      "Epoch 10/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.5822 - acc: 0.6783Epoch 1/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.5910 - acc: 0.6714 - val_loss: 0.5232 - val_acc: 0.7656\n",
      "Аккуратность на тестовых данных: 85.94%\n"
     ]
    }
   ],
   "source": [
    "vgg16_net3 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "vgg16_net3.trainable = False\n",
    "x = vgg16_net3.output\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model3 = Model(inputs=vgg16_net3.input, outputs=predictions)\n",
    "model3.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=1e-5), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model3.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "scores = model3.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NW39Z3W6yMh1"
   },
   "source": [
    "нейронка с меньшим количеством эпох (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "k7pyGtmSu9sL",
    "outputId": "a08b1da0-3aa7-4729-800c-fc8e33a790bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.7437 - acc: 0.5332Epoch 1/2\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.7520 - acc: 0.5220 - val_loss: 0.6938 - val_acc: 0.5781\n",
      "Epoch 2/2\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.7421 - acc: 0.5490Epoch 1/2\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.7370 - acc: 0.5503 - val_loss: 0.6550 - val_acc: 0.6172\n",
      "Аккуратность на тестовых данных: 59.38%\n"
     ]
    }
   ],
   "source": [
    "vgg16_net4 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "vgg16_net4.trainable = False\n",
    "x = vgg16_net4.output\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model4 = Model(inputs=vgg16_net4.input, outputs=predictions)\n",
    "model4.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=1e-5), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model4.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=2,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "scores = model4.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9nUd8aq4y1bv"
   },
   "source": [
    "нейронка с меньшим количеством эпох (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "ohgdjA25u9pl",
    "outputId": "6774eb78-eafb-4bb3-e257-577fb446528d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.7536 - acc: 0.5262Epoch 1/5\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.7490 - acc: 0.5252 - val_loss: 0.6750 - val_acc: 0.5312\n",
      "Epoch 2/5\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6911 - acc: 0.5781Epoch 1/5\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.6880 - acc: 0.5818 - val_loss: 0.6413 - val_acc: 0.5859\n",
      "Epoch 3/5\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6838 - acc: 0.5927Epoch 1/5\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.6873 - acc: 0.5881 - val_loss: 0.6138 - val_acc: 0.6484\n",
      "Epoch 4/5\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6385 - acc: 0.6319Epoch 1/5\n",
      "10/10 [==============================] - 172s 17s/step - loss: 0.6359 - acc: 0.6313 - val_loss: 0.5909 - val_acc: 0.7031\n",
      "Epoch 5/5\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 0.6181 - acc: 0.6461Epoch 1/5\n",
      "10/10 [==============================] - 171s 17s/step - loss: 0.6109 - acc: 0.6646 - val_loss: 0.5686 - val_acc: 0.7031\n",
      "Аккуратность на тестовых данных: 80.47%\n"
     ]
    }
   ],
   "source": [
    "vgg16_net5 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "vgg16_net5.trainable = False\n",
    "x = vgg16_net5.output\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model5 = Model(inputs=vgg16_net5.input, outputs=predictions)\n",
    "model5.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=1e-5), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model5.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "scores = model5.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "JfH91vnovmab",
    "outputId": "020cab8c-4904-4c60-df32-3c67252a13e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      " 9/10 [==========================>...] - ETA: 13s - loss: 0.8602 - acc: 0.4931Epoch 1/13\n",
      "10/10 [==============================] - 166s 17s/step - loss: 0.8521 - acc: 0.4921 - val_loss: 0.7145 - val_acc: 0.5000\n",
      "Epoch 2/13\n",
      " 9/10 [==========================>...] - ETA: 13s - loss: 0.7747 - acc: 0.5000Epoch 1/13\n",
      "10/10 [==============================] - 166s 17s/step - loss: 0.7752 - acc: 0.5031 - val_loss: 0.6725 - val_acc: 0.5938\n",
      "Epoch 3/13\n",
      " 9/10 [==========================>...] - ETA: 13s - loss: 0.7606 - acc: 0.5295Epoch 1/13\n",
      "10/10 [==============================] - 166s 17s/step - loss: 0.7638 - acc: 0.5234 - val_loss: 0.6406 - val_acc: 0.6406\n",
      "Epoch 4/13\n",
      " 9/10 [==========================>...] - ETA: 13s - loss: 0.7500 - acc: 0.5559Epoch 1/13\n",
      "10/10 [==============================] - 165s 16s/step - loss: 0.7446 - acc: 0.5613 - val_loss: 0.6129 - val_acc: 0.6797\n",
      "Epoch 5/13\n",
      " 9/10 [==========================>...] - ETA: 13s - loss: 0.6561 - acc: 0.6144Epoch 1/13\n",
      "10/10 [==============================] - 163s 16s/step - loss: 0.6535 - acc: 0.6187 - val_loss: 0.5911 - val_acc: 0.6953\n",
      "Epoch 6/13\n",
      " 9/10 [==========================>...] - ETA: 13s - loss: 0.6474 - acc: 0.6354Epoch 1/13\n",
      "10/10 [==============================] - 165s 16s/step - loss: 0.6409 - acc: 0.6336 - val_loss: 0.5665 - val_acc: 0.6953\n",
      "Epoch 7/13\n",
      " 9/10 [==========================>...] - ETA: 13s - loss: 0.6221 - acc: 0.6562Epoch 1/13\n",
      "10/10 [==============================] - 166s 17s/step - loss: 0.6238 - acc: 0.6578 - val_loss: 0.5475 - val_acc: 0.7109\n",
      "Epoch 8/13\n",
      " 9/10 [==========================>...] - ETA: 13s - loss: 0.5544 - acc: 0.7010Epoch 1/13\n",
      "10/10 [==============================] - 164s 16s/step - loss: 0.5510 - acc: 0.7075 - val_loss: 0.5317 - val_acc: 0.7109\n",
      "Epoch 9/13\n",
      " 9/10 [==========================>...] - ETA: 13s - loss: 0.5796 - acc: 0.6958Epoch 1/13\n",
      "10/10 [==============================] - 166s 17s/step - loss: 0.5729 - acc: 0.7060 - val_loss: 0.5151 - val_acc: 0.7422\n",
      "Epoch 10/13\n",
      " 9/10 [==========================>...] - ETA: 13s - loss: 0.5215 - acc: 0.7325Epoch 1/13\n",
      "10/10 [==============================] - 165s 16s/step - loss: 0.5185 - acc: 0.7358 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 11/13\n",
      " 9/10 [==========================>...] - ETA: 13s - loss: 0.5044 - acc: 0.7622Epoch 1/13\n",
      "10/10 [==============================] - 165s 16s/step - loss: 0.5010 - acc: 0.7689 - val_loss: 0.4886 - val_acc: 0.7734\n",
      "Epoch 12/13\n",
      " 9/10 [==========================>...] - ETA: 13s - loss: 0.4999 - acc: 0.7674Epoch 1/13\n",
      "10/10 [==============================] - 164s 16s/step - loss: 0.5073 - acc: 0.7626 - val_loss: 0.4742 - val_acc: 0.7734\n",
      "Epoch 13/13\n",
      " 9/10 [==========================>...] - ETA: 13s - loss: 0.4758 - acc: 0.7867Epoch 1/13\n",
      "10/10 [==============================] - 166s 17s/step - loss: 0.4741 - acc: 0.7893 - val_loss: 0.4660 - val_acc: 0.7969\n",
      "Аккуратность на тестовых данных: 84.38%\n"
     ]
    }
   ],
   "source": [
    "vgg16_net6 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "vgg16_net6.trainable = False\n",
    "x = vgg16_net6.output\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model6 = Model(inputs=vgg16_net6.input, outputs=predictions)\n",
    "model6.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=1e-5), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model6.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=13,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "scores = model6.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab6-Transfer-Learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
